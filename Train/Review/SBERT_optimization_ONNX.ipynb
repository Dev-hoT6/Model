{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 환경 설정\n",
        "### 패키지 설치 및 임포트"
      ],
      "metadata": {
        "id": "5QCU2oBilrSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U sentence-transformers\n",
        "%pip install onnxruntime\n",
        "%pip install onnx"
      ],
      "metadata": {
        "id": "79Xqzb92u1Lo",
        "outputId": "5aa353cb-5af7-4a3a-c6fa-c951a408eb71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LXxMcCxX2UK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.onnx\n",
        "import onnxruntime as ort\n",
        "import onnx\n",
        "from onnx import shape_inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yazJSdAxmO-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df86a7a-2297-412c-bd59-a5c654165b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### working directory 설정"
      ],
      "metadata": {
        "id": "loNUu5hJmAmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR_PATH = os.getcwd()\n",
        "BASE_DIR_PATH = os.path.join(BASE_DIR_PATH, 'drive', 'MyDrive','dev','final')\n",
        "MODEL_DIR_PATH = os.path.join(BASE_DIR_PATH, 'model')\n",
        "\n",
        "TEXT_MODEL_SAVE_PATH = os.path.join(MODEL_DIR_PATH, 'S-Transformer.pt')"
      ],
      "metadata": {
        "id": "pC4dziAImCdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Export to ONNX"
      ],
      "metadata": {
        "id": "IhA3z3MymeoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'snunlp/KR-SBERT-V40K-klueNLI-augSTS'\n",
        "\n",
        "# 모델, 토크나이저\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 평가모드 전환\n",
        "model.eval()\n",
        "\n",
        "# 더미 입력\n",
        "dummy_text = [\"this is a sample text\"]\n",
        "inputs = tokenizer(dummy_text, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# 모델 내보내기\n",
        "onnx_model_path = \"SBERT_original.onnx\"\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (inputs['input_ids'], inputs['attention_mask']),\n",
        "    onnx_model_path,\n",
        "    export_params=True,  # 학습 가중치  저장\n",
        "    opset_version=11,  # 임의 설정\n",
        "    do_constant_folding=True,  # 최적화 시 상수 폴딩 사용\n",
        "    input_names=['input_ids', 'attention_mask'],\n",
        "    output_names=['last_hidden_state'],\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n",
        "        'attention_mask': {0: 'batch_size', 1: 'sequence_length'},\n",
        "        'last_hidden_state': {0: 'batch_size', 1: 'sequence_length'}\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "eWl7UVQPBueX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 최적화"
      ],
      "metadata": {
        "id": "SgaiQx6dnDRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape inference\n",
        "onnx_model = onnx.load(\"SBERT_original.onnx\")\n",
        "inferred_model = onnx.shape_inference.infer_shapes(onnx_model) # 차원정보 추론(최적화/디버깅)\n",
        "\n",
        "onnx.save(inferred_model, \"SBERT_inferred.onnx\")"
      ],
      "metadata": {
        "id": "mlAjW7ooaPU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1. 양자화"
      ],
      "metadata": {
        "id": "l5iGZP_RPzJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic\n",
        "\n",
        "inferred_model = \"SBERT_inferred.onnx\"\n",
        "quant_model = \"SBERT_quant.onnx\"\n",
        "quantize_dynamic(inferred_model, quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mouq0gbJ21_D",
        "outputId": "dbc276ad-0c40-48ed-cdf1-9a67dfc62612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul_1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2. 전처리 후 양자화"
      ],
      "metadata": {
        "id": "pymlL6iQP1Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_quant_model = \"SBERT_pre_quant.onnx\"\n",
        "onnxruntime.quantization.quant_pre_process(inferred_model,pre_quant_model,skip_symbolic_shape=True)"
      ],
      "metadata": {
        "id": "Jpd3Eom_ObgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_quant_model = \"SBERT_pre_quant.onnx\"\n",
        "after_pre_quant_model = \"SBERT_quant_after_pre.onnx\"\n",
        "quantize_dynamic(pre_quant_model, after_pre_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WHerQ_LPY6m",
        "outputId": "c9a9d3fe-9c81-450a-d11b-adbe2eb612c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul_1]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul]\n",
            "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul_1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-3. fp16"
      ],
      "metadata": {
        "id": "PmVeJAN-P3yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.transformers import optimizer\n",
        "optimized_model = optimizer.optimize_model(\"SBERT_inferred.onnx\", model_type='bert', num_heads=12, hidden_size=768)\n",
        "optimized_model.convert_float_to_float16()\n",
        "optimized_model.save_model_to_file(\"SBERT_fp16.onnx\")"
      ],
      "metadata": {
        "id": "aFgWmR3xGlUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 용량 확인\n",
        "!ls -alh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OncDC9Mi6WB8",
        "outputId": "57f21bac-1b3e-4fb4-b862-ce201fb5dcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.8G\n",
            "drwxr-xr-x 1 root root 4.0K Jan 17 02:30 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan 17 00:17 ..\n",
            "drwxr-xr-x 4 root root 4.0K Jan 12 19:19 .config\n",
            "drwx------ 6 root root 4.0K Jan 17 00:20 drive\n",
            "drwxr-xr-x 2 root root 4.0K Jan 17 00:33 .ipynb_checkpoints\n",
            "drwxr-xr-x 1 root root 4.0K Jan 12 19:20 sample_data\n",
            "-rw-r--r-- 1 root root 223M Jan 17 02:16 SBERT_fp16.onnx\n",
            "-rw-r--r-- 1 root root 446M Jan 17 01:05 SBERT_inferred.onnx\n",
            "-rw-r--r-- 1 root root 446M Jan 17 00:33 SBERT_original.onnx\n",
            "-rw-r--r-- 1 root root 446M Jan 17 02:25 SBERT_pre_quant.onnx\n",
            "-rw-r--r-- 1 root root 113M Jan 17 02:30 SBERT_quant_after_pre.onnx\n",
            "-rw-r--r-- 1 root root 113M Jan 17 01:40 SBERT_quant.onnx\n",
            "-rw-r--r-- 1 root root 263K Jan 17 02:24 sym_shape_infer_temp.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Inference"
      ],
      "metadata": {
        "id": "fAYZ4ZkjeoKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "onnx_model_path = \"SBERT_fp16.onnx\"\n",
        "ort_session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "input_data = ['이 옷 예쁘네요','원단이 마음에 들어요', '색감이 예뻐요']\n",
        "encoded_input = tokenizer(input_data, padding=True, truncation=True)\n",
        "\n",
        "outputs = ort_session.run(None, {\"input_ids\": encoded_input['input_ids'],\"attention_mask\": encoded_input['attention_mask']})\n",
        "\n",
        "print(outputs[0].shape)\n",
        "print(outputs[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCbgq9bhJwaQ",
        "outputId": "c8a4859b-a6fe-4f03-a683-ce9afe3abee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 6, 768)\n",
            "(3, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 속도 비교"
      ],
      "metadata": {
        "id": "yyGFpcRLpqZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "input_data = ['이 옷 예쁘네요','원단이 마음에 들어요', '색감이 예뻐요']\n",
        "encoded_input = tokenizer(input_data, padding=True, truncation=True)\n",
        "\n",
        "sbert_model_name = ['SBERT_original.onnx', 'SBERT_inferred.onnx', 'SBERT_quant.onnx', 'SBERT_quant_after_pre.onnx', 'SBERT_fp16.onnx']\n",
        "\n",
        "for model in sbert_model_name:\n",
        "  session = ort.InferenceSession(model)\n",
        "  start = time.time()\n",
        "  outputs = ort_session.run(None, {\"input_ids\": encoded_input['input_ids'],\"attention_mask\": encoded_input['attention_mask']})\n",
        "  end = time.time()\n",
        "  print(model,\"session time: \", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmRaimiTymsr",
        "outputId": "e589ccfc-bd80-4bde-b07c-0e3f2c6a3ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SBERT_original.onnx session time:  1.4432239532470703\n",
            "SBERT_inferred.onnx session time:  0.867927074432373\n",
            "SBERT_quant.onnx session time:  1.0061850547790527\n",
            "SBERT_quant_after_pre.onnx session time:  0.9265992641448975\n",
            "SBERT_fp16.onnx session time:  0.6180510520935059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkDlSZfuSjZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}